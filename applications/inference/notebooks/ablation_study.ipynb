{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../assets\")\n",
    "sys.path.append(\"../\")\n",
    "from experiments import NonStationaryDDMExperiment\n",
    "from models import MixtureRandomWalkDDM, RegimeSwitchingDDM, RandomWalkDDM, LevyFlightDDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Suppress scientific notation for floats\n",
    "np.set_printoptions(suppress=True)\n",
    "# Configure rng\n",
    "RNG = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OBS = 768\n",
    "NUM_SAMPLES = 2000\n",
    "NUM_RESIMULATIONS = 500\n",
    "\n",
    "LOCAL_PARAM_LABELS = ['Drift rate', 'Threshold', 'Non-decision time']\n",
    "LOCAL_PARAM_NAMES  = [r'v', r'a', r'\\tau']\n",
    "MODEL_NAMES = [\n",
    "    'Random walk DDM', 'Mixture random walk DDM',\n",
    "    'Levy flight DDM', 'Regime switching DDM'\n",
    "    ]\n",
    "CONDITION_NAMES = [\"Accuracy Condition\", \"Speed Condition\"]\n",
    "YLABEL = [\n",
    "    \"Response time (s)\", \"Response time (s)\", \"Accuracy\", \"Accuracy\",\n",
    "    \"Drift rate\", \"Drift rate\", \"Threshold\", \"Threshold\"\n",
    "    ]\n",
    "BAR_WIDTH = np.arange(-0.5, 0.7, 0.25)\n",
    "X_AXIS_VALUES = np.arange(4) * 1.5\n",
    "LABELS = [\n",
    "    'Empiric', 'Random walk', 'Mixture random walk',\n",
    "    'Levy flight', 'Regime switching'\n",
    "    ]\n",
    "COLORS = [\n",
    "    \"black\", \"orange\", \"maroon\", \"#133a76\", \"green\"\n",
    "]\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.serif'] = \"Palatino\"\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_model = RandomWalkDDM()\n",
    "rw_trainer = NonStationaryDDMExperiment(\n",
    "    rw_model,\n",
    "    summary_network_type=\"smoothing\",\n",
    "    checkpoint_path=\"../checkpoints/smoothing_random_walk_ddm\",\n",
    "    skip_checks=True\n",
    ")\n",
    "\n",
    "mrw_model = MixtureRandomWalkDDM()\n",
    "mrw_trainer = NonStationaryDDMExperiment(\n",
    "    mrw_model,\n",
    "    summary_network_type=\"smoothing\",\n",
    "    checkpoint_path=\"../checkpoints/smoothing_mixture_random_walk_ddm\",\n",
    "    skip_checks=True\n",
    ")\n",
    "\n",
    "lf_model = LevyFlightDDM()\n",
    "lf_trainer = NonStationaryDDMExperiment(\n",
    "    lf_model,\n",
    "    summary_network_type=\"smoothing\",\n",
    "    checkpoint_path=\"../checkpoints/smoothing_levy_flight_ddm\",\n",
    "    skip_checks=True\n",
    ")\n",
    "\n",
    "rs_model = RegimeSwitchingDDM()\n",
    "rs_trainer = NonStationaryDDMExperiment(\n",
    "    rs_model,\n",
    "    summary_network_type=\"smoothing\",\n",
    "    checkpoint_path=\"../checkpoints/smoothing_regime_switching_ddm\",\n",
    "    skip_checks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rw_model, mrw_model, lf_model, rs_model]\n",
    "trainers = [rw_trainer, mrw_trainer, lf_trainer, rs_trainer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_color_discrimination.csv')\n",
    "data['rt'] = np.where(data['correct'] == 0, -data['rt'], data['rt'])\n",
    "\n",
    "NUM_SUBJECTS = len(np.unique(data['id']))\n",
    "emp_data = np.zeros((NUM_SUBJECTS, NUM_OBS, 1), dtype=np.float32)\n",
    "for i in range(NUM_SUBJECTS):\n",
    "    tmp = data[data['id'] == i+1]\n",
    "    emp_data[i] = tmp['rt'].to_numpy()[:, np.newaxis]\n",
    "\n",
    "data['trial'] = np.tile(np.arange(NUM_OBS) + 1, NUM_SUBJECTS)\n",
    "data['rt'] = np.abs(data['rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(model, trainer, max_obs):\n",
    "    num_local_params = model.local_prior_means.shape[0]\n",
    "    local_samples_z = np.zeros((NUM_SUBJECTS, max_obs, NUM_SAMPLES, num_local_params))\n",
    "    with tf.device('/cpu:0'):\n",
    "        for i in range(NUM_SUBJECTS):\n",
    "            subject_data = {'summary_conditions': emp_data[i:i+1, :max_obs]}\n",
    "            samples = trainer.amortizer.sample(subject_data, NUM_SAMPLES)\n",
    "            local_samples_z[i] = samples['local_samples']\n",
    "    local_samples = local_samples_z * model.local_prior_stds + model.local_prior_means\n",
    "    return local_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_OBS = [int(NUM_OBS*(1/8)), int(NUM_OBS*(1/4)), int(NUM_OBS*(1/2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_ablation = []\n",
    "for max_obs in MAX_OBS:\n",
    "    samples_per_model = []\n",
    "    for i in tqdm(range(len(models))):\n",
    "        samples = model_inference(models[i], trainers[i], max_obs)\n",
    "        samples_per_model.append(samples)\n",
    "    samples_per_ablation.append(samples_per_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result_summary(summaries, max_obs, figsize=(18, 8)):\n",
    "    FONT_SIZE_1 = 22\n",
    "    FONT_SIZE_2 = 21\n",
    "    FONT_SIZE_3 = 18\n",
    "    handles = []\n",
    "    fig, axarr = plt.subplots(2, 4, figsize=figsize)\n",
    "    which_summary = np.repeat(np.arange(4), 2)\n",
    "    which_condition = np.tile([0, 1], 4)\n",
    "    for i, ax in enumerate(axarr.flat):\n",
    "        summary = summaries[which_summary[i]]\n",
    "        if i < 4:\n",
    "            colors = [\"black\", \"orange\", \"maroon\", \"#133a76\", \"green\"]\n",
    "        else:\n",
    "            colors = [\"orange\", \"maroon\", \"#133a76\", \"green\"]\n",
    "        for t, sumsum in enumerate(summary):\n",
    "            ax.scatter(\n",
    "                X_AXIS_VALUES + BAR_WIDTH[t],\n",
    "                sumsum.loc[sumsum.speed_condition == which_condition[i], 'point_estimate'],\n",
    "                s=75, color=colors[t], label=LABELS[t]\n",
    "            )\n",
    "            ax.errorbar(\n",
    "                X_AXIS_VALUES + BAR_WIDTH[t],\n",
    "                sumsum.loc[sumsum.speed_condition == which_condition[i], 'point_estimate'],\n",
    "                yerr=sumsum.loc[sumsum.speed_condition == which_condition[i], 'error'],\n",
    "                fmt='o', color=colors[t], markersize=8, elinewidth=2, capsize=0\n",
    "                )\n",
    "            handles.append(\n",
    "                Line2D(\n",
    "                    xdata=[], ydata=[], marker='o', markersize=10, lw=3,\n",
    "                    color=colors[t], label=LABELS[t]\n",
    "                )\n",
    "            )\n",
    "        ax.set_title(CONDITION_NAMES[which_condition[i]], pad=20, fontsize=FONT_SIZE_1)\n",
    "        x_labels = ['1', '2', '3', '4']\n",
    "        x_positions = X_AXIS_VALUES\n",
    "        ax.set_xticks(x_positions, x_labels)\n",
    "        if i < 2:\n",
    "            ax.set_ylim([\n",
    "                summary[0][\"point_estimate\"].min() - 0.1,\n",
    "                summary[0][\"point_estimate\"].max() + 0.4\n",
    "                ])\n",
    "        elif i < 4:\n",
    "            ax.set_ylim([0.4, 1.05])\n",
    "        elif i < 6:\n",
    "            ax.set_ylim([\n",
    "                summary[0][\"point_estimate\"].min() - 1.0,\n",
    "                summary[0][\"point_estimate\"].max() + 2.5\n",
    "                ])\n",
    "        else:\n",
    "            ax.set_ylim([\n",
    "                summary[0][\"point_estimate\"].min() - 0.25,\n",
    "                summary[0][\"point_estimate\"].max() + 0.4\n",
    "                ])\n",
    "        ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "        ax.set_ylabel(YLABEL[i], labelpad=10, fontsize=FONT_SIZE_2)\n",
    "        if i > 3:\n",
    "            ax.set_xlabel(\"Difficulty\", labelpad=10, fontsize=FONT_SIZE_2)\n",
    "        ax.grid(alpha=0.4)\n",
    "    # legend\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    fig.legend(\n",
    "        handles,\n",
    "        LABELS,\n",
    "        fontsize=FONT_SIZE_2, bbox_to_anchor=(0.5, -0.05),\n",
    "        loc=\"center\", ncol=5\n",
    "        )\n",
    "    sns.despine()\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    fig.suptitle(f'N = {max_obs}', fontsize=26, fontweight='semibold', y=1.05)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, max_obs in enumerate(MAX_OBS):\n",
    "    sub_data = data[data.trial <= MAX_OBS[j]]\n",
    "    # compute overall empiric rt summaries\n",
    "    grouped_data = sub_data.groupby(['speed_condition', 'difficulty'])\n",
    "    rt_summary = grouped_data.agg({\n",
    "        'rt': ['median', lambda x: np.median(np.abs(x - np.median(x)))]\n",
    "    }).reset_index(drop=False)\n",
    "    rt_summary.columns = ['speed_condition', 'difficulty', 'point_estimate', 'error']\n",
    "    # compute overall empiric acc summaries\n",
    "    grouped_data = sub_data.groupby(['id', 'speed_condition', 'difficulty'])\n",
    "    acc_summary = grouped_data.agg({\n",
    "        'correct': ['mean']\n",
    "    }).reset_index(drop=False)\n",
    "    acc_summary.columns = ['id', 'speed_condition', 'difficulty', 'accuracy']\n",
    "    grouped_data = acc_summary.groupby(['speed_condition', 'difficulty'])\n",
    "    acc_summary = grouped_data.agg({\n",
    "        'accuracy': ['median', lambda x: np.median(np.abs(x - np.median(x)))]\n",
    "    }).reset_index(drop=False)\n",
    "    acc_summary.columns = ['speed_condition', 'difficulty', 'point_estimate', 'error']\n",
    "\n",
    "    # iterate over model and subjects\n",
    "    rt_summary_per_model = []\n",
    "    acc_summary_per_model = []\n",
    "    v_summary_per_model = []\n",
    "    a_summary_per_model = []\n",
    "    resim_data_per_model = []\n",
    "    posteriors_per_model = []\n",
    "    rt_summary_per_model.append(rt_summary)\n",
    "    acc_summary_per_model.append(acc_summary)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        resim_data = np.zeros((NUM_SUBJECTS, NUM_RESIMULATIONS, max_obs, 6))\n",
    "        person_samples = np.zeros((NUM_SUBJECTS, max_obs, NUM_SAMPLES, 5))\n",
    "        for sub in range(NUM_SUBJECTS):\n",
    "            # compute indiviudal summaries\n",
    "            person_data = sub_data.loc[sub_data.id == sub+1]\n",
    "            # posterior re-simulation for all models\n",
    "            idx = np.random.choice(np.arange(NUM_SAMPLES), NUM_RESIMULATIONS, replace=False)\n",
    "            pred_data = model.likelihood(samples_per_ablation[j][i][sub, :, idx, :])['sim_data']\n",
    "            pred_rt = np.abs(pred_data[:, :, None])\n",
    "            pred_correct = np.where(np.sign(pred_data) == -1, 0, 1)[:, :, None]\n",
    "            condition = np.tile(person_data['speed_condition'], (NUM_RESIMULATIONS, 1))[:, :, None]\n",
    "            difficulty = np.tile(person_data['difficulty'], (NUM_RESIMULATIONS, 1))[:, :, None]\n",
    "            id = np.full((NUM_RESIMULATIONS, max_obs, 1), sub+1)\n",
    "            sim_seq = np.repeat(np.arange(NUM_RESIMULATIONS), max_obs).reshape((NUM_RESIMULATIONS, max_obs, 1))\n",
    "            resim_data[sub] = np.c_[id, sim_seq, pred_rt, pred_correct, condition, difficulty]\n",
    "        resim_data_per_model.append(resim_data)\n",
    "        # summarize drift rate and threshold posterior\n",
    "        samples = samples_per_ablation[j][i]\n",
    "        difficulty = sub_data.difficulty.to_numpy().reshape((14, max_obs, 1))\n",
    "        difficulty = np.repeat(difficulty, 2000, axis=2)[:, :, :, np.newaxis]\n",
    "        condition = sub_data.speed_condition.to_numpy().reshape((14, max_obs, 1))\n",
    "        condition = np.repeat(condition, 2000, axis=2)[:, :, :, np.newaxis]\n",
    "        samples = np.c_[condition, difficulty, samples]\n",
    "        reshaped_data = samples.reshape(-1, 5)\n",
    "        df = pd.DataFrame(reshaped_data, columns=['speed_condition', 'difficulty', 'v', 'a', 'tau'])\n",
    "        grouped_data = df.groupby(['speed_condition', 'difficulty'])\n",
    "        summary = grouped_data.agg({\n",
    "            'v': ['median', lambda x: np.median(np.abs(x - np.median(x)))],\n",
    "            'a': ['median', lambda x: np.median(np.abs(x - np.median(x)))]\n",
    "        }).reset_index(drop=False)\n",
    "        summary.columns = ['speed_condition', 'difficulty', 'v_median', 'v_mad', 'a_median', 'a_mad']\n",
    "        v_summary = summary[['speed_condition', 'difficulty', 'v_median', 'v_mad']]\n",
    "        v_summary.columns = ['speed_condition', 'difficulty', 'point_estimate', 'error']\n",
    "        a_summary = summary[['speed_condition', 'difficulty', 'a_median', 'a_mad']]\n",
    "        a_summary.columns = ['speed_condition', 'difficulty', 'point_estimate', 'error']\n",
    "        v_summary_per_model.append(v_summary)\n",
    "        a_summary_per_model.append(a_summary)\n",
    "        # overall re-simulation\n",
    "        reshaped_data = resim_data.reshape(-1, 6)\n",
    "        df = pd.DataFrame(reshaped_data, columns=['id', 'sim', 'rt', 'correct', 'speed_condition', 'difficulty'])\n",
    "        # summarize rts\n",
    "        grouped_data = df.groupby(['speed_condition', 'difficulty'])\n",
    "        summary = grouped_data.agg({\n",
    "            'rt': ['median', lambda x: np.median(np.abs(x - np.median(x)))]\n",
    "        })\n",
    "        summary = summary.reset_index(drop=False)\n",
    "        summary.columns = ['speed_condition', 'difficulty', 'point_estimate', 'error']\n",
    "        rt_summary_per_model.append(summary)\n",
    "        # summarize accuracy\n",
    "        grouped_data = df.groupby(['id', 'sim', 'speed_condition', 'difficulty'])\n",
    "        summary = grouped_data.agg({\n",
    "            'correct': ['mean']\n",
    "        }).reset_index(drop=False)\n",
    "        summary.columns = ['id', 'sim', 'speed_condition', 'difficulty', 'accuracy']\n",
    "        grouped_data = summary.groupby(['speed_condition', 'difficulty'])\n",
    "        summary = grouped_data.agg({\n",
    "            'accuracy': ['median', lambda x: np.median(np.abs(x - np.median(x)))]\n",
    "        }).reset_index(drop=False)\n",
    "        summary.columns = ['speed_condition', 'difficulty', 'point_estimate', 'error']\n",
    "        acc_summary_per_model.append(summary)\n",
    "    summary_list = [rt_summary_per_model, acc_summary_per_model, v_summary_per_model, a_summary_per_model]\n",
    "    f = plot_result_summary(summary_list, max_obs)\n",
    "    f.savefig(f\"../plots/ablation_results_n_{max_obs}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
