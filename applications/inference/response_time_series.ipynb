{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukas/opt/miniconda3/envs/beef/lib/python3.11/site-packages/bayesflow/trainers.py:27: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "from scipy.stats import levy_stable\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../assets\")\n",
    "\n",
    "from helpers import get_setup\n",
    "from configurations import model_names, default_bounds\n",
    "from likelihoods import _sample_diffusion_trial, sample_non_stationary_diffusion_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Palatino\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "\n",
    "NUM_OBS = 768\n",
    "NUM_SUBS = 14\n",
    "NUM_SAMPLES = 1000\n",
    "HORIZON_SIZE = 68\n",
    "NUM_RESIMS = 250\n",
    "\n",
    "RNG = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sma(data, period=5):\n",
    "    j = next(i for i, x in enumerate(data) if x is not None)\n",
    "    our_range = range(len(data))[j + period - 1:]\n",
    "    empty_list = [None] * (j + period - 1)\n",
    "    sub_result = [np.mean(data[i - period + 1: i + 1]) for i in our_range]\n",
    "    return np.array(empty_list + sub_result)\n",
    "\n",
    "def post_resim(samples, num_resims):\n",
    "    num_obs = samples.shape[0]\n",
    "    num_samples = samples.shape[1]\n",
    "    idx = np.arange(0, num_samples-1, num_samples/num_resims, dtype=np.int32)\n",
    "    theta = samples[:, idx]\n",
    "    pred_data = np.zeros((num_resims, num_obs))\n",
    "    for sim in range(num_resims):\n",
    "        pred_data[sim] = np.abs(sample_non_stationary_diffusion_process(theta[:, sim]))\n",
    "    return pred_data\n",
    "\n",
    "def get_next_theta(theta_t, eta, model_name,\n",
    "                   lower_bounds=default_bounds[\"lower\"],\n",
    "                   upper_bounds=default_bounds[\"upper\"]):\n",
    "    theta_next = np.zeros(3)\n",
    "    if model_name == \"mrw\":\n",
    "        z = RNG.normal(size=(3))\n",
    "        switch_samples = RNG.random(size=(2))\n",
    "        stay = switch_samples > eta[3:]\n",
    "        # transition model\n",
    "        # update v\n",
    "        if stay[0]:\n",
    "            theta_next[0] = np.clip(\n",
    "                theta_t[0] + eta[0] * z[0],\n",
    "                a_min=lower_bounds[0], a_max=upper_bounds[0]\n",
    "            )\n",
    "        else:\n",
    "            theta_next[0] = RNG.uniform(lower_bounds[0], upper_bounds[0])\n",
    "        # update a\n",
    "        if stay[1]:\n",
    "            theta_next[1] = np.clip(\n",
    "                theta_t[1] + eta[1] * z[1],\n",
    "                a_min=lower_bounds[1], a_max=upper_bounds[1]\n",
    "            )\n",
    "        else:\n",
    "            theta_next[1] = RNG.uniform(lower_bounds[1], upper_bounds[1])\n",
    "            # update tau\n",
    "        theta_next[2] = np.clip(\n",
    "            theta_t[2] + eta[2] * z[2],\n",
    "            a_min=lower_bounds[2], a_max=upper_bounds[2]\n",
    "        )\n",
    "    if model_name == \"lf\":\n",
    "        levy_scale = np.clip(eta[:2] / np.sqrt(2), a_min=0.0000001, a_max=np.inf)\n",
    "        z_norm = RNG.normal(size=1)\n",
    "        z_levy = levy_stable.rvs(np.clip(eta[3:], a_min=0.01, a_max=2.0), 0, scale=levy_scale, size=2)\n",
    "        # update v and a\n",
    "        theta_next[:2] = np.clip(\n",
    "            theta_t[:2] + z_levy,\n",
    "            a_min=lower_bounds[:2], a_max=upper_bounds[:2]\n",
    "        )\n",
    "        # update tau\n",
    "        theta_next[2] = np.clip(\n",
    "            theta_t[2] + eta[2] * z_norm,\n",
    "            a_min=lower_bounds[2], a_max=upper_bounds[2]\n",
    "        )\n",
    "    return theta_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_color_discrimination.csv')\n",
    "with open('data/posteriors/samples_per_model.pkl', 'rb') as file:\n",
    "    samples_per_model = pickle.load(file)\n",
    "with open('data/winning_model_per_person.pkl', 'rb') as file:\n",
    "    winning_model_per_person = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Performing 2 pilot runs with the levy_flight_ddm model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 800, 3)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 800)\n",
      "INFO:root:Shape of hyper_prior_draws batch after 2 pilot simulations: (batch_size = 2, 5)\n",
      "INFO:root:Shape of local_prior_draws batch after 2 pilot simulations: (batch_size = 2, 800, 3)\n",
      "INFO:root:No shared_prior_draws provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:Loaded loss history from checkpoints/smoothing_levy_flight_ddm/history_75.pkl.\n",
      "INFO:root:Networks loaded from checkpoints/smoothing_levy_flight_ddm/ckpt-75\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n",
      "  1%|‚ñè         | 1/69 [00:17<19:59, 17.65s/it]"
     ]
    }
   ],
   "source": [
    "pred_data = np.zeros((NUM_SUBS, NUM_RESIMS, NUM_OBS))\n",
    "for sub in range(NUM_SUBS):\n",
    "    winning_model = winning_model_per_person[sub]\n",
    "    model, trainer = get_setup(model_names[winning_model], \"smoothing\")\n",
    "    person_data = data.loc[data.id == sub + 1]\n",
    "    person_rt = np.where(person_data['correct'] == 0, -person_data['rt'], person_data['rt'])[None, :, None]\n",
    "    tmp_post = trainer.amortizer.sample({\"summary_conditions\": person_rt[:, :NUM_OBS-HORIZON_SIZE, :]}, 500)\n",
    "    tmp_local = tmp_post['local_samples'] * model.local_prior_stds + model.local_prior_means\n",
    "    tmp_hyper = tmp_post['global_samples'] * model.hyper_prior_stds + model.hyper_prior_means\n",
    "    for i in tqdm(range(HORIZON_SIZE+1)):\n",
    "        tmp_post = trainer.amortizer.sample(\n",
    "            {\"summary_conditions\": person_rt[:, :NUM_OBS-(HORIZON_SIZE-i), :]}, NUM_SAMPLES\n",
    "        )\n",
    "        tmp_local = tmp_post['local_samples'] * model.local_prior_stds + model.local_prior_means\n",
    "        tmp_hyper = tmp_post['global_samples'] * model.hyper_prior_stds + model.hyper_prior_means\n",
    "        if i == 0:\n",
    "            pred_data[sub, :, :NUM_OBS-HORIZON_SIZE] = post_resim(tmp_local, NUM_RESIMS)\n",
    "        else:\n",
    "            idx = np.arange(0, NUM_SAMPLES-1, NUM_SAMPLES/NUM_RESIMS, dtype=np.int32)\n",
    "            last_theta = tmp_local[-1, idx, :]\n",
    "            last_eta = tmp_hyper[idx, :]\n",
    "            for j in range(NUM_RESIMS):\n",
    "                next_theta = get_next_theta(last_theta[j], last_eta[j], model_names[winning_model])\n",
    "                pred_data[sub, j, NUM_OBS-HORIZON_SIZE+i-1] = _sample_diffusion_trial(\n",
    "                    next_theta[0], next_theta[1], next_theta[2]\n",
    "                )\n",
    "\n",
    "np.save('data/rt_time_series_resim.npy', pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rt = np.abs(pred_data[0])\n",
    "for resim in range(NUM_RESIMS):\n",
    "    pred_rt[resim] = calc_sma(pred_rt[resim])\n",
    "pred_rt_mean = pred_rt.mean(axis=0)\n",
    "pred_rt_quantiles = np.quantile(pred_rt, [0.025, 0.975], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(NUM_OBS), calc_sma(np.abs(person_rt[0, :, 0])), color='black', alpha=0.8, lw=1)\n",
    "plt.plot(range(NUM_OBS), pred_rt_mean, color='maroon', alpha=0.8, lw=1)\n",
    "plt.fill_between(range(NUM_OBS), pred_rt_quantiles[0], pred_rt_quantiles[1], color='maroon', alpha=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
